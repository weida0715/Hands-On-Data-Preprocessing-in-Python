{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hands-On Data Preprocessing in Python\n",
    "Learn how to effectively prepare data for successful data analytics\n",
    "    \n",
    "    AUTHOR: Dr. Roy Jafari \n",
    "\n",
    "### Chapter 10: Data Cleaning Level Ⅱ- Unpack, restructure, and reformulate the table\n",
    "#### Excercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 1\n",
    "This question is regarding the difference between dataset reformulation and dataset restructuring. Answer the following questions.\n",
    "\n",
    "    a.\tIn your own words described the difference between dataset reformulation and dataset restructuring. \n",
    "    b.\tIn Example 3 of this chapter, we moved the data from month_df to predict_df. The text described the level Ⅱ data cleaning both table reformulation and table restructuring? Which one of the two happened? Is it possible that the distinction we provided for the difference between table restructuring and reformulation cannot specify which one happened? Would that matter?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 2\n",
    "For this exercise, we will be using 'LaqnData.csv' which is collected from the London Air website (https://www.londonair.org.uk/LondonAir/Default.aspx) and include the hourly readings of 5 air particles (NO, NO2, NOX, PM2.5, and PM10) from a specific cite. Perform the following steps for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    a. Read the dataset into air_df using pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b.\tUse .unique() function to identify the columns that only have one possible value and then remove them from air_df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c.\tUnpack the column readingDateTime into new columns Date and time. This can be done in different ways. The following gives you clues about three approaches you can have to do this unpacking. \n",
    "\n",
    "    i.\tUse air_df.apply()\n",
    "    ii.\tUse air_df.readingDateTime.str.split(‘ ’,expand=true)\n",
    "    iii.\tUse pd.to_datetime() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d. Use what you learned in this chapter to create the following visual. Each line in each of the 5 line plots represents one day reading for the plot’s relevant air particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " e.\tLabel and describe the data cleaning steps you did in this exercise. For example, did you have to reformulate a new dataset to draw the visualization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Excercise 3\n",
    "In this exercise, we will be using stock_index.csv. This file has hourly data for stock indices Nasdaq, S&P, and Dow Jones from Nov 7, 2019, until June 10th, 2021. Each row of data represents an hour of the trading day, and each row is described by the opening value, closing value and the volume for each of the three mentioned stock indices. The opening value is the value of the index at the beginning of the hour, the closing value is the value of the index at the end of the hour, and volume is the amount of trading that happened in that hour\n",
    "\n",
    "In this exercise, we would like to perform a clustering analysis to understand how many different types of trading days we experience during 2020. Using the following attributes that are calculable from stock_df.csv we’d like to use K-Means to cluster the stock trading days of 2020 into 4 clusters. \n",
    "\n",
    "- nasdaqChPe: Nasdaq change percentage over the trading day\n",
    "- nasdaqToVo: Total Nasdaq trading volume over the trading day\n",
    "- dowChPe: Dow Jones change percentage over the trading day\n",
    "- dowToVo: Total Dow Jones trading volume over the trading day\n",
    "- sNpChPe: S&P change percentage over the trading day\n",
    "- sNpToVo: Total S&P trading volume over the trading day\n",
    "- N_daysMarketClose: the number of days before the market closes for the weekend; for Mondays, it is 5, for Tuesdays, it is 4, for Wednesdays, it is 3, for  Thursdays, it is 2, and for Fridays, it is 0.\n",
    "\n",
    "Make sure to finish the clustering analysis with a centroid analysis via a heatmap, and give each cluster a name. Once the clustering analysis is done, also label and describe the data cleaning steps you did in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
